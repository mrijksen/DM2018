{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = [10, 6]\n",
    "pylab.rcParams[\"patch.force_edgecolor\"] = True\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the data look like?\n",
    "\n",
    "The first step is to load all the data and to take a first glance at how the data looks (size, attributes, values etcetera). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/marleen/projects/DM2018/ODI-2018.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that there are 217 records and 14 attributes (excluding the timestamp). The attributes have different types, lets discuss shortly all the attributes and their corresponding types:\n",
    "\n",
    "** 1. What program are you in? **\n",
    "This was an open question asking for the user's program (categorical). The result should be a (set of) word(s). Note here, that the user could fill in anything they wanted to which makes it difficult to categorize the data. Data cleaning is needed to group the different programs. An example: Artificial Intelligence should belong to the same category as AI. \n",
    "\n",
    "** 2. Have you taken a course on machine learning? **\n",
    "Here, the user could only specify \"yes\" or \"no\" (binary), it is therefore relatively easy to analyze this data. No cleaning is needed. There might be unknowns which have to be filtered out.\n",
    "\n",
    "** 3. Have you taken a course on information retrieval? **\n",
    "Here, 0 stands for no and 1 stands for yes (binary). The same holds as for attribute 2. \n",
    "\n",
    "** 4. Have you taken a course on databases? **\n",
    "Here, mu stands for yes and sigma stands for no (binary). The same holds as for attribute 2. \n",
    "\n",
    "** 5. What is your gender? **\n",
    "Here a user could specify male, female or unknown (categorical). Note that the unknown again might be difficult for analyzing the data.\n",
    "\n",
    "** 6. Chocolate makes you.... **\n",
    "The possible answers here were 'neither', 'I have no idea what you are talking about' or 'fat' (categorical). \n",
    "\n",
    "** 7. When is your birthday (date)? **\n",
    "This was an open question meaning that the user could choose how to write down it's birthday. This makes it difficult to analyze since there are many ways to do so (a better way would be to present a calendar to the user in which it can choose a dat). Data cleaning might become involved here! This is somewhat continuous data. \n",
    "\n",
    "** 8. Number of neighbours sitting around you **\n",
    "Here a user could write anything. Data cleaning is important here. Maybe values are written like words. \n",
    "\n",
    "** 9. Did you stand up? **\n",
    "Possible answers: yes, no and unknown. (Categorical)\n",
    "\n",
    "** 10. You can get £100... **\n",
    "Here the user could fill in anything they wanted to. Note that the maximum should be 100 pounds. Data cleaning is really necessary here since some users have valus too high and others used words. (Continuous)\n",
    "\n",
    "** 11. Give a random number **\n",
    "Can be any number (or word?) data cleaning necessary. (Continuous)\n",
    "\n",
    "** 12. Time you went to bed **\n",
    "Needs cleaning, different users specify time in different ways (AM, PM, words, 10:23, 10.32 etcetera). Continuous.\n",
    "\n",
    "** 13. What makes a good day for you (1) and (2)? **\n",
    "User could type anything they want. Cleaning might not be necessary (except for non existing words or numbers maybe). Categorical\n",
    "\n",
    "### Relationships between attributes \n",
    "\n",
    "It is possible to hypothesize which attributes have relationships. For example, a users program (1) probably relates to the courses they have followed (2, 3 and 4). \n",
    "\n",
    "Also, gender might tell something about the program a user follows (in some programs it is known that there are more males/females). \n",
    "\n",
    "(12) might influence the answers given in (13). \n",
    "\n",
    "Also, (8) and (9) might have a relationship. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study Program\n",
    "\n",
    "\n",
    "Try to categorize study programs in:\n",
    "- Artificial intelligence\n",
    "- Business analytics\n",
    "- Computer Science\n",
    "- Computational Science\n",
    "- Bioinformatics\n",
    "- Econometrics and operation research\n",
    "- Quantitative Risk Management\n",
    "- PhD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make copy of original dataset\n",
    "df2 = df.copy()\n",
    "\n",
    "# remove first row\n",
    "df2 = df2.drop(df.index[0])\n",
    "\n",
    "# turn column into type string\n",
    "df2['What programme are you in?'] = df2['What programme are you in?'].apply(str)\n",
    "\n",
    "# computational science\n",
    "searchfor = ['Computational', 'CLS', 'CSL']\n",
    "df2.loc[df2['What programme are you in?'].str.contains('|'.join(searchfor), case=False), \\\n",
    "        'What programme are you in?'] = 'Computational Science'\n",
    "\n",
    "# computer science\n",
    "searchfor = ['Computer', 'Big data engineering']\n",
    "df2.loc[df2['What programme are you in?'].str.contains('|'.join(searchfor), case=False), \\\n",
    "        'What programme are you in?'] = 'Computer Science'\n",
    "df2['What programme are you in?']=df2['What programme are you in?'].replace('cs', 'Computer Science')\n",
    "df2['What programme are you in?']=df2['What programme are you in?'].replace('CS', 'Computer Science')\n",
    "\n",
    "# artificial science\n",
    "searchfor = ['A. I.', 'Ai', 'Artificial', 'Intelligence']\n",
    "df2.loc[df2['What programme are you in?'].str.contains('|'.join(searchfor), case=False), \\\n",
    "        'What programme are you in?'] = 'Artificial Intelligence'\n",
    "\n",
    "# phds\n",
    "searchfor = ['phd']\n",
    "df2.loc[df2['What programme are you in?'].str.contains('|'.join(searchfor), case=False), \\\n",
    "        'What programme are you in?'] = 'PhD'\n",
    "\n",
    "# Quantitative Risk Management\n",
    "searchfor = ['QRM', 'Duisenberg', 'Risk management']\n",
    "df2.loc[df2['What programme are you in?'].str.contains('|'.join(searchfor), case=False), \\\n",
    "        'What programme are you in?'] = 'Quantitative Risk Management'\n",
    "\n",
    "# Bioinformatics\n",
    "searchfor = ['Bioinformatics', 'Biology', 'bio']\n",
    "df2.loc[df2['What programme are you in?'].str.contains('|'.join(searchfor), case=False), \\\n",
    "        'What programme are you in?'] = 'Bioinformatics'\n",
    "df2['What programme are you in?']=df2['What programme are you in?'].replace('Bioinformatcis', 'Bioinformatics')\n",
    "\n",
    "# Business Analytics\n",
    "searchfor = ['Business Analytics']\n",
    "df2.loc[df2['What programme are you in?'].str.contains('|'.join(searchfor), case=False), \\\n",
    "        'What programme are you in?'] = 'Business Analytics'\n",
    "df2['What programme are you in?']=df2['What programme are you in?'].replace('BA', 'Business Analytics')\n",
    "\n",
    "# Econometrics & Operations Research\n",
    "searchfor = ['EOR', 'Operations']\n",
    "df2.loc[df2['What programme are you in?'].str.contains('|'.join(searchfor), case=False), \\\n",
    "        'What programme are you in?'] = 'Econometrics & Operations Research'\n",
    "df2['What programme are you in?']=df2['What programme are you in?'].replace('OR', 'Econometrics & Operations Research')\n",
    "\n",
    "# Econometrics\n",
    "df2['What programme are you in?']=df2['What programme are you in?'].replace('Econometrics ', 'Econometrics')\n",
    "\n",
    "# Set programs with < 2 people to 'Other' category\n",
    "value_counts = df2['What programme are you in?'].value_counts()\n",
    "to_remove = value_counts[value_counts <= 2].index\n",
    "df2['What programme are you in?'].replace(to_remove, 'Other', inplace=True)\n",
    "\n",
    "# make extra column containing labels\n",
    "df2[\"What programme are you in?\"] = df2[\"What programme are you in?\"].astype('category')\n",
    "df2[\"programme_cat\"] = df2[\"What programme are you in?\"].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Dates\n",
    "\n",
    "This is quite involved, since there are many ways in which the date is provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# change column name and type\n",
    "df3 = df2.copy()\n",
    "df3 = df3.rename(columns={'When is your birthday (date)?': 'birthday'})\n",
    "# df3[['birthday']]=df3[['birthday']].astype(str)\n",
    "\n",
    "# necessary replacements\n",
    "replace_dict = {\"/\":\"-\", \" \":\"-\", \" \":\"-\", \".\":\"-\"} \n",
    "for initial, replace in replace_dict.items():\n",
    "    df3['birthday']=df3['birthday'].str.replace(initial, replace)\n",
    "\n",
    "# replace items without '-' by np.nan\n",
    "for item in df3['birthday']:\n",
    "    if (\"-\" in item)==False:\n",
    "#         df3['birthday'][df3['birthday'] == item] = \"NaN\"\n",
    "        df3['birthday'].loc[df3['birthday'] == item] = \"NaN\"\n",
    "        \n",
    "# change words into numbers for months\n",
    "replace_dict = {\"january\":\"1\", \"february\":\"2\", \"march\":\"3\", \"april\":\"4\", \"may\":\"5\",\\\n",
    "                \"june\":\"6\", \"july\":\"7\", \"august\":\"8\", \"september\":\"9\", \"october\":\"10\",\\\n",
    "               \"november\":\"11\", \"december\":\"12\"} \n",
    "for initial, replace in replace_dict.items():\n",
    "    df3['birthday']=df3['birthday'].str.replace(initial, replace, case=False)\n",
    "\n",
    "# set all dates to day-month format\n",
    "j=0\n",
    "for item in df3['birthday']:\n",
    "    itemcopy=item\n",
    "    date = item.split('-')\n",
    "    \n",
    "    # check if still words in dates, remove\n",
    "    try:\n",
    "        for i in range(len(date)):\n",
    "            int(date[i])\n",
    "    except:\n",
    "        df3['birthday'].iloc[j] = \"NaN\"\n",
    "        item=\"NaN\"\n",
    "        j+=1\n",
    "        continue\n",
    "    \n",
    "    # remove birth years\n",
    "    try:\n",
    "        tempdate=date.copy()\n",
    "        for i in range(len(date)):\n",
    "            if int(date[i]) > 31:\n",
    "                tempdate.remove(date[i])\n",
    "                newitem = \"-\".join(tempdate)\n",
    "                df3['birthday'].iloc[j]=newitem\n",
    "                item = newitem\n",
    "    except ValueError as e:\n",
    "        df3['birthday'].iloc[j] = \"NaN\"\n",
    "        item=\"NaN\"\n",
    "        j+=1\n",
    "        continue\n",
    "\n",
    "    # put day and month in correct order\n",
    "    try:\n",
    "        date=item.split(\"-\")\n",
    "        if int(date[0])>12 and int(date[1])>12:\n",
    "            raise Exception        \n",
    "        elif int(date[1])>12:\n",
    "            month=date[0]\n",
    "            day=date[1]\n",
    "            newitem=[day,month]\n",
    "            df3['birthday'].iloc[j]=\"-\".join(newitem)\n",
    "            item=\"-\".join(newitem)\n",
    "    except (Exception, ValueError) as e:\n",
    "        df3['birthday'].iloc[j]=\"NaN\"\n",
    "        item=\"NaN\"\n",
    "        j+=1\n",
    "        continue   \n",
    "            \n",
    "    # remove zeroes\n",
    "    try:\n",
    "        date=item.split('-')\n",
    "        date[0]=str(int(date[0]))\n",
    "        date[1]=str(int(date[1]))\n",
    "        df3['birthday'].iloc[j]=\"-\".join(date)\n",
    "        item=\"-\".join(date)\n",
    "        \n",
    "    except:\n",
    "        df3['birthday'].iloc[j] = \"NaN\"\n",
    "        item=\"NaN\"\n",
    "        j+=1\n",
    "        continue\n",
    "        \n",
    "    # remove days\n",
    "    try:\n",
    "        int(item.split(\"-\")[1])\n",
    "        df3['birthday'].iloc[j] = (item.split(\"-\")[1])\n",
    "        j+=1\n",
    "    except:\n",
    "        df3['birthday'].iloc[j] = \"NaN\"\n",
    "        item=\"NaN\"\n",
    "        j+=1\n",
    "        continue\n",
    "\n",
    "df3['birthday']=df3['birthday'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Random Numbers\n",
    "\n",
    "This is easier, we will only consider numbers between 0 and 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column name and type\n",
    "df4 = df3.copy()\n",
    "df4 = df4.rename(columns={'Give a random number': 'random_number'})\n",
    "\n",
    "# iterate over all random numbers\n",
    "for item in df4['random_number']:\n",
    "    try:\n",
    "        newitem=float(item)\n",
    "        \n",
    "        # remove everything larger than 10\n",
    "        if newitem > 10:\n",
    "            raise Exception\n",
    "        elif newitem < 0:\n",
    "            raise Exception\n",
    "    except:\n",
    "        df4['random_number'][df4['random_number']==item]=\"NaN\"\n",
    "df4['random_number']=df4['random_number'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Greedyness Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column name and type\n",
    "df5 = df4.copy()\n",
    "df5 = df5.rename(columns={'You can get £100 if you win a local DM competition, or we don’t hold any competitions and I give everyone some money (not the same amount!). How much do you think you would get then? ': 'greedyness'})\n",
    "df5[['greedyness']]=df5[['greedyness']].astype(str)\n",
    "\n",
    "# remove pounds stuff\n",
    "remove_dict=({'£':\"\", \"pond\":\"\",\"euro\":\"\",\"pound\":\"\",\"€ ?:)\":\"\",\"euros\":\"\"})\n",
    "for initial, replace in remove_dict.items():\n",
    "    try:\n",
    "        df5['greedyness']=df5['greedyness'].str.replace(initial, replace)\n",
    "    except:\n",
    "        x=1\n",
    "\n",
    "# greedyness needs to be between 0 and 100\n",
    "df5['greedyness']=pd.to_numeric(df5['greedyness'], errors='coerce')\n",
    "mask = ((df5.greedyness > 100)| (df5.greedyness < 0) )\n",
    "# print(mask)\n",
    "column_name = 'greedyness'\n",
    "df5.loc[mask, column_name] = np.nan\n",
    "\n",
    "#turn all values into cents and make integers of it\n",
    "df5.greedyness=df5.greedyness.dropna() * 100\n",
    "df5.greedyness=df5.greedyness.dropna().astype(int)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Gender Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change column name and type\n",
    "df6 = df5.copy()\n",
    "df6 = df6.rename(columns={'What is your gender?': 'gender'})\n",
    "\n",
    "# replacements\n",
    "replace_dict=({'male':1,'female':0,'unknown':\"NaN\"})\n",
    "for initial, new in replace_dict.items():\n",
    "    df6.gender=df6.gender.replace(initial, new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Courses Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6.copy()\n",
    "df7 = df7.rename(columns={'Have you taken a course on machine learning?': 'machine_learning'})\n",
    "df7 = df7.rename(columns={'Have you taken a course on information retrieval?': 'info_retrieval'})\n",
    "df7 = df7.rename(columns={'Have you taken a course on databases?': 'databases'})\n",
    "df7 = df7.rename(columns={'Have you taken a course on statistics?': 'statistics'})\n",
    "\n",
    "# replacements for machine learning\n",
    "replace_dict=({'yes':1,'no':0,'unknown':\"NaN\"})\n",
    "for initial, new in replace_dict.items():\n",
    "    df7.machine_learning=df7.machine_learning.replace(initial, new)\n",
    "    \n",
    "# replacements for info retrieval\n",
    "replace_dict=({'unknown':\"NaN\"})\n",
    "for initial, new in replace_dict.items():\n",
    "    df7.info_retrieval=df7.info_retrieval.replace(initial, new)\n",
    "\n",
    "# replacements for databases\n",
    "replace_dict=({'ja':1,'nee':0,'unknown':\"NaN\"})\n",
    "for initial, new in replace_dict.items():\n",
    "    df7.databases=df7.databases.replace(initial, new)\n",
    "\n",
    "# replacements for statistics\n",
    "replace_dict=({'mu':1,'sigma':0,'unknown':\"NaN\"})\n",
    "for initial, new in replace_dict.items():\n",
    "    df7.statistics=df7.statistics.replace(initial, new)\n",
    "\n",
    "# make integers of all courses\n",
    "df7.statistics = df7.statistics.astype(float)\n",
    "df7.info_retrieval = df7.info_retrieval.astype(float)\n",
    "df7.machine_learning = df7.machine_learning.astype(float)\n",
    "df7.databases = df7.databases.astype(float)\n",
    "\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of final columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df8=df7.copy()\n",
    "df8 = df8.rename(columns={'What makes a good day for you (1)?': 'good_day_1'})\n",
    "df8 = df8.rename(columns={'What makes a good day for you (2)?': 'good_day_2'})\n",
    "df8['length_answers'] = 0\n",
    "df8.length_answers.astype(int)\n",
    "for i in range(1,len(df8.good_day_1) + 1):\n",
    "    df8.loc[i,('length_answers')] = len(df8.loc[i, 'good_day_1'])+len(df8.loc[i, 'good_day_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some nice figures, distributions and plots from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['What programme are you in?'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.hist(column='birthday', bins=np.arange(0.5,13.5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.hist(column='random_number', bins=np.arange(-0.5,10.5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y-axis in bold\n",
    "rc('font', weight='bold')\n",
    " \n",
    "# Values of each group\n",
    "study_groups_male=list(df4['What programme are you in?'][df4['What is your gender?']==\"male\"].value_counts().sort_index())\n",
    "study_groups_female=list(df4['What programme are you in?'][df4['What is your gender?']==\"female\"].value_counts().sort_index())\n",
    "print(df4['What programme are you in?'][df4['What is your gender?']==\"male\"].value_counts().sort_index())\n",
    "print(df4['What programme are you in?'][df4['What is your gender?']==\"female\"].value_counts().sort_index())\n",
    "bars = [x + y for x, y in zip(study_groups_male, study_groups_female)]\n",
    " \n",
    "# position of the bars \n",
    "r = [1,2,3,4,5,6,7,8,9,10]\n",
    " \n",
    "# names of group and bar width\n",
    "names = ['Artificial Intelligence','Bioinformatics','Business Analytics','Computational Science',\\\n",
    "         'Computer Science','Econometrics','Econometrics & Operations Research',\\\n",
    "         'Other','PhD','Quantitative Risk Management']\n",
    "barWidth = 1\n",
    " \n",
    "# ticks\n",
    "plt.xticks(rotation=82)\n",
    "plt.xticks(r, names, fontweight='bold')\n",
    "plt.xlabel(\"group\")\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df5[['greedyness','What programme are you in?','What is your gender?']]\n",
    "value_counts = df5['What programme are you in?'].value_counts()\n",
    "to_remove = value_counts[value_counts <= 20].index\n",
    "\n",
    "# subset['What programme are you in?'].replace(to_remove, \"NaN\", inplace=True)\n",
    "subset['What programme are you in?'].replace(to_remove, \"NaN\", inplace=True)\n",
    "subset = subset[subset['What programme are you in?'] != 'NaN']\n",
    "\n",
    "# subset['What programme are you in?'] = subset.programme_cat.astype(float)\n",
    "subset = subset.dropna()\n",
    "fig, ax = pyplot.subplots(figsize=(7,4))\n",
    "\n",
    "# sns.boxplot(x=df5.greedyness / 100,y=df5['What programme are you in?'])\n",
    "sns.boxplot(ax=ax,x=subset.greedyness / 100,y=subset['What is your gender?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting by seaborn\n",
    "sns.boxplot(x=df5.random_number,y=df5['What programme are you in?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting by seaborn\n",
    "sns.boxplot(x=df5.random_number,y=df5['What is your gender?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting by seaborn\n",
    "sns.boxplot(x=df8.length_answers,y=df5['What programme are you in?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot % of people who followed a course for each program\n",
    "\n",
    "# total number of people in programme\n",
    "totals = np.array(df8['What programme are you in?'].value_counts().sort_index())\n",
    "\n",
    "# fraction of people following courses per programme\n",
    "statistics = np.array(df8['What programme are you in?'][df8['statistics']==1].value_counts().sort_index())*100/totals\n",
    "databases = np.array(df8['What programme are you in?'][df8['databases']==1].value_counts().sort_index())*100/totals\n",
    "machine_learning = np.array(df8['What programme are you in?'][df8['machine_learning']==1].value_counts().sort_index())*100/totals\n",
    "info_retrieval = np.array(df8['What programme are you in?'][df8['info_retrieval']==1].value_counts().sort_index())*100/totals\n",
    "\n",
    "statistics = statistics[0:5]\n",
    "databases = databases[0:5]\n",
    "machine_learning = machine_learning[0:5]\n",
    "info_retrieval = info_retrieval[0:5]\n",
    "\n",
    "# y-axis in bold\n",
    "rc('font', weight='bold')\n",
    " \n",
    "# The position of the bars on the x-axis\n",
    "# r = [1,2,3,4,5,6,7,8,9,10]\n",
    "r = [1,2,3,4,5]\n",
    " \n",
    "# Names of group and bar width\n",
    "# names = ['Artificial Intelligence','Bioinformatics','Business Analytics','Computational Science',\\\n",
    "#          'Computer Science','Econometrics','Econometrics & Operations Research',\\\n",
    "#          'Other','PhD','Quantitative Risk Management']\n",
    "# names = ['AI','BioI','BA','CLS','CS','ECO','EOR',\\\n",
    "#          'Other','PhD','QRM']\n",
    "names = ['AI','BioI','BA','CLS','CS']\n",
    "barWidth = 1\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)    \n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "\n",
    "# turn off axis lines and ticks of the big subplot\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "\n",
    "ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "# ax1.tick_params(labelcolor='w')\n",
    "# ax2.tick_params(labelcolor='w')\n",
    "\n",
    "ax3.set_xticks(r)\n",
    "ax3.set_xticklabels(names, rotation=90)\n",
    "ax4.set_xticks(r)\n",
    "ax4.set_xticklabels(names, rotation=90)\n",
    "\n",
    "names = [\"\",\"\",\"\",\"\",\"\"]\n",
    "ax1.set_xticks(r)\n",
    "ax1.set_xticklabels(names)\n",
    "ax2.set_xticks(r)\n",
    "ax2.set_xticklabels(names)\n",
    "\n",
    "ax1.bar(r, statistics, color='#0e6655', edgecolor='white', width=barWidth)\n",
    "ax2.bar(r, machine_learning, color='#0e6655', edgecolor='white', width=barWidth)\n",
    "ax3.bar(r, databases, color='#0e6655', edgecolor='white', width=barWidth)\n",
    "ax4.bar(r, info_retrieval, color='#0e6655', edgecolor='white', width=barWidth)\n",
    "\n",
    "# Set common labels\n",
    "ax.set_xlabel('Programme')\n",
    "ax.set_ylabel('Percentage of Students (%)')\n",
    "\n",
    "ax1.set_title('Statistics')\n",
    "ax2.set_title('Machine Learning')\n",
    "ax3.set_title('Databases')\n",
    "ax4.set_title('Information Retrieval')\n",
    "# plt.tight_layout()\n",
    "plt.savefig('common_labels.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting study program based on courses followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.programme_cat = df8.programme_cat.astype(int)\n",
    "df8.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop programmes with <20 students\n",
    "value_counts = df8['programme_cat'].value_counts()\n",
    "# print(value_counts)\n",
    "# to_remove = value_counts[value_counts <= 20].index\n",
    "# df8.replace(to_remove, np.nan, inplace=True)\n",
    "# df8['What programme are you in?'].drop(to_remove)\n",
    "\n",
    "feature_names = ['statistics', 'databases', 'info_retrieval', 'machine_learning']\n",
    "keep = value_counts[value_counts >= 20].index\n",
    "subset=df8[feature_names+['programme_cat']].dropna()\n",
    "\n",
    "# part_set = df8[]\n",
    "X = subset[feature_names]\n",
    "y = subset['programme_cat'].astype(int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale attribute values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "model = logreg.fit(X_train, y_train)\n",
    "# model = logreg\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(model.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=6)\n",
    "print (\"Cross-validated scores:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "model=clf\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=6)\n",
    "print (\"Cross-validated scores:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "model = gnb.fit(X_train, y_train)\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
    "     .format(gnb.score(X_train, y_train)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
    "     .format(gnb.score(X_test, y_test)))\n",
    "\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=6)\n",
    "print (\"Cross-validated scores:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedyness based on program and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above this treshold, you are greedy\n",
    "greedy_treshold = 150\n",
    "\n",
    "# create new column with 1 begin greedy 0 not greedy\n",
    "df7['greedy_indicator']=np.where(df7['greedyness']>=greedy_treshold, 1, 0)\n",
    "\n",
    "feature_names = ['programme_cat','gender']\n",
    "subset=df7[feature_names+['greedy_indicator']].dropna()\n",
    "\n",
    "\n",
    "subset.gender=subset.gender.astype(float)\n",
    "subset=subset.dropna()\n",
    "\n",
    "# remove small programmes\n",
    "value_counts = subset['programme_cat'].value_counts()\n",
    "to_remove = value_counts[value_counts <= 20].index\n",
    "subset['programme_cat'].replace(to_remove, \"NaN\", inplace=True)\n",
    "subset['programme_cat'] = subset.programme_cat.astype(float)\n",
    "subset = subset.dropna()\n",
    "# keep = value_counts[value_counts >= 20].index\n",
    "\n",
    "X = subset[feature_names]\n",
    "y = subset['greedy_indicator'].astype(int64)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# scale\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "model = logreg.fit(X_train, y_train)\n",
    "\n",
    "# model = DecisionTreeClassifier()\n",
    "# model = KNeighborsClassifier()\n",
    "# model = gnb.fit(X_train, y_train)\n",
    "# model = svm.fit(X_train, y_train)\n",
    "\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=4)\n",
    "print (\"Cross-validated scores:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# subset['multiplied']\n",
    "subset.greedy_indicator.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
