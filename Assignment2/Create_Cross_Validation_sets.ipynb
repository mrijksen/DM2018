{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efiathieniti/miniconda3/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/efiathieniti/miniconda3/envs/py35/lib/python3.5/site-packages/matplotlib/__init__.py:913: UserWarning: text.fontsize is deprecated and replaced with font.size; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from pylab import rcParams\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import pyltr\n",
    "\n",
    "import data_preprocessing\n",
    "\n",
    "\n",
    "import utils\n",
    "from operator import itemgetter\n",
    "\n",
    "import nDCG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "\n",
    "utils = imp.reload(utils)\n",
    "nDCG = imp.reload(nDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balance_flag = True\n",
    "downsampling_rate = 3\n",
    "learning_rate = 0.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training file\n",
    "df1=pd.read_pickle('cleaned_dataset_full_part1')\n",
    "df2=pd.read_pickle('cleaned_dataset_full_part2')\n",
    "df = pd.concat([df1,df2], axis=1)\n",
    "\n",
    "# add column with relevance scores\n",
    "df['relevance'] = df['booking_bool'] + df['click_bool']\n",
    "# change relevance column with relevance score (1 if clicked, 5 if booked)\n",
    "df['relevance'] = df['relevance'].map({0:0, 1:1, 2:5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = utils.define_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 files for train and test \n"
     ]
    }
   ],
   "source": [
    "#Identify groups\n",
    "groups = df['srch_id']\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "X = df[selected_features]\n",
    "y = df['relevance']\n",
    "    \n",
    "k=0\n",
    "n_splits=4\n",
    "gss = GroupShuffleSplit(n_splits=n_splits, test_size=0.3, random_state=0)\n",
    "gss_test_val = GroupShuffleSplit(n_splits=1, test_size=0.4, random_state=0)\n",
    "for train, test_val in gss.split(X, y, groups=groups):\n",
    "\n",
    "    df_train = df.iloc[train,]\n",
    "    df_train.to_pickle(\"train_\"+str(k))\n",
    "    \n",
    "    # SPlit test_val again into test and val\n",
    "    df_test_val = df.iloc[test_val,]\n",
    "    groups2 = df_test_val['srch_id']\n",
    "    # Actually we only use the first split...\n",
    "    \n",
    "    for [val_ind, test_ind] in gss_test_val.split(df_test_val[selected_features], df_test_val['relevance'], groups=groups2):\n",
    "        df_val = df_test_val.iloc[val_ind,]\n",
    "        df_test =  df_test_val.iloc[test_ind,]\n",
    "    \n",
    "    df_val.to_pickle(\"val_\"+str(k))\n",
    "    df_test.to_pickle(\"test_\"+str(k))\n",
    "    k+=1\n",
    "    print(\"Created files for k=\"+ str(k))\n",
    "\n",
    "print(\"Created %s files for train and test \"%(n_splits))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
